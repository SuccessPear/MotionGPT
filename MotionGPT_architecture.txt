MotionGPT(
  (metrics): BaseMetrics(
    (TM2TMetrics): TM2TMetrics(
      (t2m_textencoder): TextEncoderBiGRUCo(
        (pos_emb): Linear(in_features=15, out_features=300, bias=True)
        (input_emb): Linear(in_features=300, out_features=512, bias=True)
        (gru): GRU(512, 512, batch_first=True, bidirectional=True)
        (output_net): Sequential(
          (0): Linear(in_features=1024, out_features=512, bias=True)
          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (2): LeakyReLU(negative_slope=0.2, inplace=True)
          (3): Linear(in_features=512, out_features=512, bias=True)
        )
      )
      (t2m_moveencoder): MovementConvEncoder(
        (main): Sequential(
          (0): Conv1d(259, 512, kernel_size=(4,), stride=(2,), padding=(1,))
          (1): Dropout(p=0.2, inplace=True)
          (2): LeakyReLU(negative_slope=0.2, inplace=True)
          (3): Conv1d(512, 512, kernel_size=(4,), stride=(2,), padding=(1,))
          (4): Dropout(p=0.2, inplace=True)
          (5): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (out_net): Linear(in_features=512, out_features=512, bias=True)
      )
      (t2m_motionencoder): MotionEncoderBiGRUCo(
        (input_emb): Linear(in_features=512, out_features=1024, bias=True)
        (gru): GRU(1024, 1024, batch_first=True, bidirectional=True)
        (output_net): Sequential(
          (0): Linear(in_features=2048, out_features=1024, bias=True)
          (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (2): LeakyReLU(negative_slope=0.2, inplace=True)
          (3): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
    )
    (M2TMetrics): M2TMetrics(
      (t2m_textencoder): TextEncoderBiGRUCo(
        (pos_emb): Linear(in_features=15, out_features=300, bias=True)
        (input_emb): Linear(in_features=300, out_features=512, bias=True)
        (gru): GRU(512, 512, batch_first=True, bidirectional=True)
        (output_net): Sequential(
          (0): Linear(in_features=1024, out_features=512, bias=True)
          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (2): LeakyReLU(negative_slope=0.2, inplace=True)
          (3): Linear(in_features=512, out_features=512, bias=True)
        )
      )
      (t2m_moveencoder): MovementConvEncoder(
        (main): Sequential(
          (0): Conv1d(259, 512, kernel_size=(4,), stride=(2,), padding=(1,))
          (1): Dropout(p=0.2, inplace=True)
          (2): LeakyReLU(negative_slope=0.2, inplace=True)
          (3): Conv1d(512, 512, kernel_size=(4,), stride=(2,), padding=(1,))
          (4): Dropout(p=0.2, inplace=True)
          (5): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (out_net): Linear(in_features=512, out_features=512, bias=True)
      )
      (t2m_motionencoder): MotionEncoderBiGRUCo(
        (input_emb): Linear(in_features=512, out_features=1024, bias=True)
        (gru): GRU(1024, 1024, batch_first=True, bidirectional=True)
        (output_net): Sequential(
          (0): Linear(in_features=2048, out_features=1024, bias=True)
          (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (2): LeakyReLU(negative_slope=0.2, inplace=True)
          (3): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
    )
    (MMMetrics): MMMetrics(
      (t2m_textencoder): TextEncoderBiGRUCo(
        (pos_emb): Linear(in_features=15, out_features=300, bias=True)
        (input_emb): Linear(in_features=300, out_features=512, bias=True)
        (gru): GRU(512, 512, batch_first=True, bidirectional=True)
        (output_net): Sequential(
          (0): Linear(in_features=1024, out_features=512, bias=True)
          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (2): LeakyReLU(negative_slope=0.2, inplace=True)
          (3): Linear(in_features=512, out_features=512, bias=True)
        )
      )
      (t2m_moveencoder): MovementConvEncoder(
        (main): Sequential(
          (0): Conv1d(259, 512, kernel_size=(4,), stride=(2,), padding=(1,))
          (1): Dropout(p=0.2, inplace=True)
          (2): LeakyReLU(negative_slope=0.2, inplace=True)
          (3): Conv1d(512, 512, kernel_size=(4,), stride=(2,), padding=(1,))
          (4): Dropout(p=0.2, inplace=True)
          (5): LeakyReLU(negative_slope=0.2, inplace=True)
        )
        (out_net): Linear(in_features=512, out_features=512, bias=True)
      )
      (t2m_motionencoder): MotionEncoderBiGRUCo(
        (input_emb): Linear(in_features=512, out_features=1024, bias=True)
        (gru): GRU(1024, 1024, batch_first=True, bidirectional=True)
        (output_net): Sequential(
          (0): Linear(in_features=2048, out_features=1024, bias=True)
          (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (2): LeakyReLU(negative_slope=0.2, inplace=True)
          (3): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
    )
    (MRMetrics): MRMetrics()
    (PredMetrics): PredMetrics()
  )
  (vae): VQVae(
    (encoder): Encoder(
      (model): Sequential(
        (0): Conv1d(263, 512, kernel_size=(3,), stride=(1,), padding=(1,))
        (1): ReLU()
        (2): Sequential(
          (0): Conv1d(512, 512, kernel_size=(4,), stride=(2,), padding=(1,))
          (1): Resnet1D(
            (model): Sequential(
              (0): ResConv1DBlock(
                (norm1): Identity()
                (norm2): Identity()
                (activation1): ReLU()
                (activation2): ReLU()
                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,))
                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
              )
              (1): ResConv1DBlock(
                (norm1): Identity()
                (norm2): Identity()
                (activation1): ReLU()
                (activation2): ReLU()
                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
              )
              (2): ResConv1DBlock(
                (norm1): Identity()
                (norm2): Identity()
                (activation1): ReLU()
                (activation2): ReLU()
                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
              )
            )
          )
        )
        (3): Sequential(
          (0): Conv1d(512, 512, kernel_size=(4,), stride=(2,), padding=(1,))
          (1): Resnet1D(
            (model): Sequential(
              (0): ResConv1DBlock(
                (norm1): Identity()
                (norm2): Identity()
                (activation1): ReLU()
                (activation2): ReLU()
                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,))
                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
              )
              (1): ResConv1DBlock(
                (norm1): Identity()
                (norm2): Identity()
                (activation1): ReLU()
                (activation2): ReLU()
                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
              )
              (2): ResConv1DBlock(
                (norm1): Identity()
                (norm2): Identity()
                (activation1): ReLU()
                (activation2): ReLU()
                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
              )
            )
          )
        )
        (4): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
      )
    )
    (decoder): Decoder(
      (model): Sequential(
        (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
        (1): ReLU()
        (2): Sequential(
          (0): Resnet1D(
            (model): Sequential(
              (0): ResConv1DBlock(
                (norm1): Identity()
                (norm2): Identity()
                (activation1): ReLU()
                (activation2): ReLU()
                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,))
                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
              )
              (1): ResConv1DBlock(
                (norm1): Identity()
                (norm2): Identity()
                (activation1): ReLU()
                (activation2): ReLU()
                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
              )
              (2): ResConv1DBlock(
                (norm1): Identity()
                (norm2): Identity()
                (activation1): ReLU()
                (activation2): ReLU()
                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
              )
            )
          )
          (1): Upsample(scale_factor=2.0, mode='nearest')
          (2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
        )
        (3): Sequential(
          (0): Resnet1D(
            (model): Sequential(
              (0): ResConv1DBlock(
                (norm1): Identity()
                (norm2): Identity()
                (activation1): ReLU()
                (activation2): ReLU()
                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,))
                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
              )
              (1): ResConv1DBlock(
                (norm1): Identity()
                (norm2): Identity()
                (activation1): ReLU()
                (activation2): ReLU()
                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
              )
              (2): ResConv1DBlock(
                (norm1): Identity()
                (norm2): Identity()
                (activation1): ReLU()
                (activation2): ReLU()
                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
              )
            )
          )
          (1): Upsample(scale_factor=2.0, mode='nearest')
          (2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
        )
        (4): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
        (5): ReLU()
        (6): Conv1d(512, 263, kernel_size=(3,), stride=(1,), padding=(1,))
      )
    )
    (quantizer): QuantizeEMAReset()
  )
  (lm): MLM(
    (language_model): T5ForConditionalGeneration(
      (shared): Embedding(32615, 768)
      (encoder): T5Stack(
        (embed_tokens): Embedding(32615, 768)
        (block): ModuleList(
          (0): T5Block(
            (layer): ModuleList(
              (0): T5LayerSelfAttention(
                (SelfAttention): T5Attention(
                  (q): Linear(in_features=768, out_features=768, bias=False)
                  (k): Linear(in_features=768, out_features=768, bias=False)
                  (v): Linear(in_features=768, out_features=768, bias=False)
                  (o): Linear(in_features=768, out_features=768, bias=False)
                  (relative_attention_bias): Embedding(32, 12)
                )
                (layer_norm): T5LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): T5LayerFF(
                (DenseReluDense): T5DenseGatedActDense(
                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)
                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)
                  (wo): Linear(in_features=2048, out_features=768, bias=False)
                  (dropout): Dropout(p=0.1, inplace=False)
                  (act): NewGELUActivation()
                )
                (layer_norm): T5LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (1-11): 11 x T5Block(
            (layer): ModuleList(
              (0): T5LayerSelfAttention(
                (SelfAttention): T5Attention(
                  (q): Linear(in_features=768, out_features=768, bias=False)
                  (k): Linear(in_features=768, out_features=768, bias=False)
                  (v): Linear(in_features=768, out_features=768, bias=False)
                  (o): Linear(in_features=768, out_features=768, bias=False)
                )
                (layer_norm): T5LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): T5LayerFF(
                (DenseReluDense): T5DenseGatedActDense(
                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)
                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)
                  (wo): Linear(in_features=2048, out_features=768, bias=False)
                  (dropout): Dropout(p=0.1, inplace=False)
                  (act): NewGELUActivation()
                )
                (layer_norm): T5LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (final_layer_norm): T5LayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (decoder): T5Stack(
        (embed_tokens): Embedding(32615, 768)
        (block): ModuleList(
          (0): T5Block(
            (layer): ModuleList(
              (0): T5LayerSelfAttention(
                (SelfAttention): T5Attention(
                  (q): Linear(in_features=768, out_features=768, bias=False)
                  (k): Linear(in_features=768, out_features=768, bias=False)
                  (v): Linear(in_features=768, out_features=768, bias=False)
                  (o): Linear(in_features=768, out_features=768, bias=False)
                  (relative_attention_bias): Embedding(32, 12)
                )
                (layer_norm): T5LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): T5LayerCrossAttention(
                (EncDecAttention): T5Attention(
                  (q): Linear(in_features=768, out_features=768, bias=False)
                  (k): Linear(in_features=768, out_features=768, bias=False)
                  (v): Linear(in_features=768, out_features=768, bias=False)
                  (o): Linear(in_features=768, out_features=768, bias=False)
                )
                (layer_norm): T5LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (2): T5LayerFF(
                (DenseReluDense): T5DenseGatedActDense(
                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)
                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)
                  (wo): Linear(in_features=2048, out_features=768, bias=False)
                  (dropout): Dropout(p=0.1, inplace=False)
                  (act): NewGELUActivation()
                )
                (layer_norm): T5LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (1-11): 11 x T5Block(
            (layer): ModuleList(
              (0): T5LayerSelfAttention(
                (SelfAttention): T5Attention(
                  (q): Linear(in_features=768, out_features=768, bias=False)
                  (k): Linear(in_features=768, out_features=768, bias=False)
                  (v): Linear(in_features=768, out_features=768, bias=False)
                  (o): Linear(in_features=768, out_features=768, bias=False)
                )
                (layer_norm): T5LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): T5LayerCrossAttention(
                (EncDecAttention): T5Attention(
                  (q): Linear(in_features=768, out_features=768, bias=False)
                  (k): Linear(in_features=768, out_features=768, bias=False)
                  (v): Linear(in_features=768, out_features=768, bias=False)
                  (o): Linear(in_features=768, out_features=768, bias=False)
                )
                (layer_norm): T5LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (2): T5LayerFF(
                (DenseReluDense): T5DenseGatedActDense(
                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)
                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)
                  (wo): Linear(in_features=2048, out_features=768, bias=False)
                  (dropout): Dropout(p=0.1, inplace=False)
                  (act): NewGELUActivation()
                )
                (layer_norm): T5LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (final_layer_norm): T5LayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (lm_head): Linear(in_features=768, out_features=32615, bias=False)
    )
  )
  (_losses): ModuleDict(
    (losses_train): GPTLosses()
    (losses_test): GPTLosses()
    (losses_val): GPTLosses()
  )
)

